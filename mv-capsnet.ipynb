{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# !cat /proc/cpuinfo","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\"\"\"\nSome key layers used for constructing a Capsule Network. These layers can used to construct CapsNet on other dataset, \nnot just on MNIST.\n*NOTE*: some functions can be implemented in multiple ways, I keep all of them. You can try them for yourself just by\nuncommenting them and commenting their counterparts.\nAuthor: Xifeng Guo, E-mail: `guoxifeng1990@163.com`, Github: `https://github.com/XifengGuo/CapsNet-Keras`\n\"\"\"\n\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras import initializers, layers\n\n\nclass Length(layers.Layer):\n    \"\"\"\n    Compute the length of vectors. This is used to compute a Tensor that has the same shape with y_true in margin_loss.\n    Using this layer as model's output can directly predict labels by using `y_pred = np.argmax(model.predict(x), 1)`\n    inputs: shape=[None, num_vectors, dim_vector]\n    output: shape=[None, num_vectors]\n    \"\"\"\n    def call(self, inputs, **kwargs):\n        return tf.sqrt(tf.reduce_sum(tf.square(inputs), -1) + K.epsilon())\n\n    def compute_output_shape(self, input_shape):\n        return input_shape[:-1]\n\n    def get_config(self):\n        config = super(Length, self).get_config()\n        return config\n\n\nclass Mask(layers.Layer):\n    \"\"\"\n    Mask a Tensor with shape=[None, num_capsule, dim_vector] either by the capsule with max length or by an additional \n    input mask. Except the max-length capsule (or specified capsule), all vectors are masked to zeros. Then flatten the\n    masked Tensor.\n    For example:\n        ```\n        x = keras.layers.Input(shape=[8, 3, 2])  # batch_size=8, each sample contains 3 capsules with dim_vector=2\n        y = keras.layers.Input(shape=[8, 3])  # True labels. 8 samples, 3 classes, one-hot coding.\n        out = Mask()(x)  # out.shape=[8, 6]\n        # or\n        out2 = Mask()([x, y])  # out2.shape=[8,6]. Masked with true labels y. Of course y can also be manipulated.\n        ```\n    \"\"\"\n    def call(self, inputs, **kwargs):\n        if type(inputs) is list:  # true label is provided with shape = [None, n_classes], i.e. one-hot code.\n            assert len(inputs) == 2\n            inputs, mask = inputs\n        else:  # if no true label, mask by the max length of capsules. Mainly used for prediction\n            # compute lengths of capsules\n            x = tf.sqrt(tf.reduce_sum(tf.square(inputs), -1))\n            # generate the mask which is a one-hot code.\n            # mask.shape=[None, n_classes]=[None, num_capsule]\n            mask = tf.one_hot(indices=tf.argmax(x, 1), depth=x.shape[1])\n\n        # inputs.shape=[None, num_capsule, dim_capsule]\n        # mask.shape=[None, num_capsule]\n        # masked.shape=[None, num_capsule * dim_capsule]\n        masked = K.batch_flatten(inputs * tf.expand_dims(mask, -1))\n        return masked\n\n    def compute_output_shape(self, input_shape):\n        if type(input_shape[0]) is tuple:  # true label provided\n            return tuple([None, input_shape[0][1] * input_shape[0][2]])\n        else:  # no true label provided\n            return tuple([None, input_shape[1] * input_shape[2]])\n\n    def get_config(self):\n        config = super(Mask, self).get_config()\n        return config\n\n\ndef squash(vectors, axis=-1):\n    \"\"\"\n    The non-linear activation used in Capsule. It drives the length of a large vector to near 1 and small vector to 0\n    :param vectors: some vectors to be squashed, N-dim tensor\n    :param axis: the axis to squash\n    :return: a Tensor with same shape as input vectors\n    \"\"\"\n    s_squared_norm = tf.reduce_sum(tf.square(vectors), axis, keepdims=True)\n    scale = s_squared_norm / (1 + s_squared_norm) / tf.sqrt(s_squared_norm + K.epsilon())\n    return scale * vectors\n\n\nclass CapsuleLayer(layers.Layer):\n    \"\"\"\n    The capsule layer. It is similar to Dense layer. Dense layer has `in_num` inputs, each is a scalar, the output of the\n    neuron from the former layer, and it has `out_num` output neurons. CapsuleLayer just expand the output of the neuron\n    from scalar to vector. So its input shape = [None, input_num_capsule, input_dim_capsule] and output shape = \\\n    [None, num_capsule, dim_capsule]. For Dense Layer, input_dim_capsule = dim_capsule = 1.\n    :param num_capsule: number of capsules in this layer\n    :param dim_capsule: dimension of the output vectors of the capsules in this layer\n    :param routings: number of iterations for the routing algorithm\n    \"\"\"\n    def __init__(self, num_capsule, dim_capsule, routings=3,\n                 kernel_initializer='glorot_uniform',\n                 **kwargs):\n        super(CapsuleLayer, self).__init__(**kwargs)\n        self.num_capsule = num_capsule\n        self.dim_capsule = dim_capsule\n        self.routings = routings\n        self.kernel_initializer = initializers.get(kernel_initializer)\n\n    def build(self, input_shape):\n        assert len(input_shape) >= 3, \"The input Tensor should have shape=[None, input_num_capsule, input_dim_capsule]\"\n        self.input_num_capsule = input_shape[1]\n        self.input_dim_capsule = input_shape[2]\n\n        # Transform matrix, from each input capsule to each output capsule, there's a unique weight as in Dense layer.\n        self.W = self.add_weight(shape=[self.num_capsule, self.input_num_capsule,\n                                        self.dim_capsule, self.input_dim_capsule],\n                                 initializer=self.kernel_initializer,\n                                 name='W')\n\n        self.built = True\n\n    def call(self, inputs, training=None):\n        # inputs.shape=[None, input_num_capsule, input_dim_capsule]\n        # inputs_expand.shape=[None, 1, input_num_capsule, input_dim_capsule, 1]\n        inputs_expand = tf.expand_dims(tf.expand_dims(inputs, 1), -1)\n\n        # Replicate num_capsule dimension to prepare being multiplied by W\n        # inputs_tiled.shape=[None, num_capsule, input_num_capsule, input_dim_capsule, 1]\n        inputs_tiled = tf.tile(inputs_expand, [1, self.num_capsule, 1, 1, 1])\n\n        # Compute `inputs * W` by scanning inputs_tiled on dimension 0.\n        # W.shape=[num_capsule, input_num_capsule, dim_capsule, input_dim_capsule]\n        # x.shape=[num_capsule, input_num_capsule, input_dim_capsule, 1]\n        # Regard the first two dimensions as `batch` dimension, then\n        # matmul(W, x): [..., dim_capsule, input_dim_capsule] x [..., input_dim_capsule, 1] -> [..., dim_capsule, 1].\n        # inputs_hat.shape = [None, num_capsule, input_num_capsule, dim_capsule]\n        inputs_hat = tf.squeeze(tf.map_fn(lambda x: tf.matmul(self.W, x), elems=inputs_tiled))\n\n        # Begin: Routing algorithm ---------------------------------------------------------------------#\n        # The prior for coupling coefficient, initialized as zeros.\n        # b.shape = [None, self.num_capsule, 1, self.input_num_capsule].\n        b = tf.zeros(shape=[inputs.shape[0], self.num_capsule, 1, self.input_num_capsule])\n\n        assert self.routings > 0, 'The routings should be > 0.'\n        for i in range(self.routings):\n            # c.shape=[batch_size, num_capsule, 1, input_num_capsule]\n            c = tf.nn.softmax(b, axis=1)\n\n            # c.shape = [batch_size, num_capsule, 1, input_num_capsule]\n            # inputs_hat.shape=[None, num_capsule, input_num_capsule, dim_capsule]\n            # The first two dimensions as `batch` dimension,\n            # then matmal: [..., 1, input_num_capsule] x [..., input_num_capsule, dim_capsule] -> [..., 1, dim_capsule].\n            # outputs.shape=[None, num_capsule, 1, dim_capsule]\n            outputs = squash(tf.matmul(c, inputs_hat))  # [None, 10, 1, 16]\n\n            if i < self.routings - 1:\n                # outputs.shape =  [None, num_capsule, 1, dim_capsule]\n                # inputs_hat.shape=[None, num_capsule, input_num_capsule, dim_capsule]\n                # The first two dimensions as `batch` dimension, then\n                # matmal:[..., 1, dim_capsule] x [..., input_num_capsule, dim_capsule]^T -> [..., 1, input_num_capsule].\n                # b.shape=[batch_size, num_capsule, 1, input_num_capsule]\n                b += tf.matmul(outputs, inputs_hat, transpose_b=True)\n        # End: Routing algorithm -----------------------------------------------------------------------#\n\n        return tf.squeeze(outputs)\n\n    def compute_output_shape(self, input_shape):\n        return tuple([None, self.num_capsule, self.dim_capsule])\n\n    def get_config(self):\n        config = {\n            'num_capsule': self.num_capsule,\n            'dim_capsule': self.dim_capsule,\n            'routings': self.routings\n        }\n        base_config = super(CapsuleLayer, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n\n\ndef PrimaryCap(inputs, dim_capsule, n_channels, kernel_size, strides, padding):\n    \"\"\"\n    Apply Conv2D `n_channels` times and concatenate all capsules\n    :param inputs: 4D tensor, shape=[None, width, height, channels]\n    :param dim_capsule: the dim of the output vector of capsule\n    :param n_channels: the number of types of capsules\n    :return: output tensor, shape=[None, num_capsule, dim_capsule]\n    \"\"\"\n    output = layers.Conv2D(filters=dim_capsule*n_channels, kernel_size=kernel_size, strides=strides, padding=padding,\n                           name='primarycap_conv2d')(inputs)\n    outputs = layers.Reshape(target_shape=[-1, dim_capsule], name='primarycap_reshape')(output)\n    return layers.Lambda(squash, name='primarycap_squash')(outputs)\n\n\nclass ViewPoolingLayer(layers.Layer):\n\n    def __init__(self, num_views, **kwargs):\n        super(ViewPoolingLayer, self).__init__(**kwargs)\n        self.num_views = num_views\n        self.tf_num_views = tf.constant(self.num_views)\n\n    def build(self, input_shape):\n        self.n_per_view = tf.divide(input_shape[0], self.tf_num_views)\n        self.built = True\n    \n    def call(self, inputs, **kwargs):\n        reshaped = K.reshape(\n            inputs,\n            (self.n_per_view, self.tf_num_views, inputs.shape[-1])\n        )\n        result = K.max(reshaped, axis=1)\n        return tf.repeat(result, repeats=self.num_views, axis=0)\n\n    def compute_output_shape(self, input_shape):\n        return input_shape\n\n    def get_config(self):\n        config = super(ViewPoolingLayer, self).get_config()\n        return config\n\n\nclass ViewCapsReshapeLayer(layers.Layer):\n\n    def __init__(self, num_caps, **kwargs):\n        super(ViewCapsReshapeLayer, self).__init__(**kwargs)\n        self.num_caps = num_caps\n\n    def call(self, inputs, **kwargs):\n        return K.reshape(\n            inputs, (-1, self.num_caps, inputs.shape[-1])\n        )\n\n    def compute_output_shape(self, input_shape):\n        return tuple(\n            int(input_shape[0] / self.num_caps),\n            self.num_caps, inputs.shape[-1]\n        )\n\n    def get_config(self):\n        config = super(ViewCapsReshapeLayer, self).get_config()\n        return config\n\n    \nclass ViewCapsRepeatLayer(layers.Layer):\n\n    def __init__(self, num_views, **kwargs):\n        super(ViewCapsRepeatLayer, self).__init__(**kwargs)\n        self.num_views = num_views\n\n    def call(self, inputs, **kwargs):\n        return tf.repeat(inputs, repeats=self.num_views, axis=0)\n\n    def compute_output_shape(self, input_shape):\n        return tuple(\n            input_shape[0] * self.num_views,\n            inputs.shape[-2], inputs.shape[-1]\n        )\n\n    def get_config(self):\n        config = super(ViewCapsRepeatLayer, self).get_config()\n        return config\n\n\ndef ViewCapsuleLayer(inputs, num_views, dim_capsule, routings):\n    n_class = inputs.shape[1]\n    reshaped = ViewCapsReshapeLayer(\n        num_caps=num_views * n_class, name='viewcaps_reshape'\n    )(inputs)\n    view_caps = CapsuleLayer(\n        num_capsule=n_class, dim_capsule=dim_capsule, routings=routings, name='viewcaps'\n    )(reshaped)\n    return ViewCapsRepeatLayer(num_views=num_views, name='viewcaps_rep')(view_caps)\n\n\n\"\"\"\n# The following is another way to implement primary capsule layer. This is much slower.\n# Apply Conv2D `n_channels` times and concatenate all capsules\ndef PrimaryCap(inputs, dim_capsule, n_channels, kernel_size, strides, padding):\n    outputs = []\n    for _ in range(n_channels):\n        output = layers.Conv2D(filters=dim_capsule, kernel_size=kernel_size, strides=strides, padding=padding)(inputs)\n        outputs.append(layers.Reshape([output.get_shape().as_list()[1] ** 2, dim_capsule])(output))\n    outputs = layers.Concatenate(axis=1)(outputs)\n    return layers.Lambda(squash)(outputs)\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom keras.callbacks import Callback\nfrom sklearn.metrics import f1_score\n\n\nclass F1_score(Callback):\n    \n    def __init__(self, val_gen, val_steps, save_dir, model_type, batch_size):\n        self.val_gen = val_gen\n        self.val_steps = val_steps\n        self.save_dir = save_dir\n        self.model_type = model_type\n        self.batch_size = batch_size\n\n    def on_train_begin(self, logs={}):\n        self.val_f1s = []\n        \n\n    def on_epoch_end(self, epoch, logs={}):\n        all_true = None\n        all_pred = None\n        for batch_index in range(self.val_steps):\n            (xy, yx) = next(self.val_gen)\n            y_pred, _ = self.model.predict((xy, yx), batch_size=self.batch_size)\n            y_pred_1hot = np.zeros_like(y_pred)\n            y_pred_1hot[np.arange(len(y_pred)), y_pred.argmax(1)] = 1\n            if all_true is not None:\n                all_true = np.concatenate((all_true, xy[1].astype(int)))\n            else:\n                all_true = xy[1].astype(int)\n            if all_pred is not None:\n                all_pred = np.concatenate((all_pred, y_pred_1hot.astype(int)))\n            else:\n                all_pred = y_pred_1hot.astype(int)\n\n        val_f1_weighted = f1_score(all_true, all_pred, average='weighted')\n        val_f1_micro = f1_score(all_true, all_pred, average='micro')\n        val_f1_macro = f1_score(all_true, all_pred, average='macro')\n        self.val_f1s.append((epoch, val_f1_weighted, val_f1_micro, val_f1_macro))\n        (\n            pd.DataFrame(self.val_f1s, columns=['epoch', 'val_f1_weighted', 'val_f1_micro', 'val_f1_macro'])\n                .to_csv(f'{self.save_dir}/{self.model_type}_f1.csv', index=False)\n        )        \n        print(f'— f1: weighted - {val_f1_weighted}, micro - {val_f1_micro}, macro - {val_f1_macro}')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"\"\"\"\nKeras implementation of CapsNet in Hinton's paper Dynamic Routing Between Capsules.\nThe current version maybe only works for TensorFlow backend. Actually it will be straightforward to re-write to TF code.\nAdopting to other backends should be easy, but I have not tested this. \n\nUsage:\n       python capsulenet.py\n       python capsulenet.py --epochs 50\n       python capsulenet.py --epochs 50 --routings 3\n       ... ...\n       \nResult:\n    Validation accuracy > 99.5% after 20 epochs. Converge to 99.66% after 50 epochs.\n    About 110 seconds per epoch on a single GTX1070 GPU card\n    \nAuthor: Xifeng Guo, E-mail: `guoxifeng1990@163.com`, Github: `https://github.com/XifengGuo/CapsNet-Keras`\n\"\"\"\n\nimport numpy as np\nfrom keras import layers, models, optimizers\nfrom keras import backend as K\nimport tensorflow as tf\nfrom keras.utils import to_categorical\nfrom PIL import Image\nimport os\nimport argparse\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import callbacks\nimport pandas as pd\n\nK.set_image_data_format('channels_last')\nWORK_DIR = './../input/views-rendered-from-3d-models/cleaned.dataset/'\nFILE_PATH_COLUMN = 'file_path'\nCLASS_COLUMN = 'label'\n# image_width, image_height = 224, 224\n# image_width, image_height = 30, 30\nimage_width, image_height = 45, 45\n\n\ndef CapsNet(input_shape, n_class, routings, batch_size):\n    \"\"\"\n    A Capsule Network on MNIST.\n    :param input_shape: data shape, 3d, [width, height, channels]\n    :param n_class: number of classes\n    :param routings: number of routing iterations\n    :param batch_size: size of batch\n    :return: Two Keras Models, the first one used for training, and the second one for evaluation.\n            `eval_model` can also be used for training.\n    \"\"\"\n    x = layers.Input(shape=input_shape, batch_size=batch_size)\n\n    # Layer 1: Just a conventional Conv2D layer\n    conv1 = layers.Conv2D(filters=256, kernel_size=9, strides=1, padding='valid', activation='relu', name='conv1')(x)\n\n    # Layer 2: Conv2D layer with `squash` activation, then reshape to [None, num_capsule, dim_capsule]\n    primarycaps = PrimaryCap(conv1, dim_capsule=8, n_channels=32, kernel_size=9, strides=2, padding='valid')\n\n    # Layer 3: Capsule layer. Routing algorithm works here.\n    caps_layer1 = CapsuleLayer(num_capsule=n_class, dim_capsule=16, routings=routings, name='caps1')(primarycaps)\n\n    # Layer 4: This is an auxiliary layer to replace each capsule with its length. Just to match the true label's shape.\n    # If using tensorflow, this will not be necessary. :)\n    out_caps = Length(name='capsnet')(caps_layer1)\n\n    # Decoder network.\n    y = layers.Input(shape=(n_class,), name='recon_input')\n    masked_by_y = Mask(name='mask')([caps_layer1, y])  # The true label is used to mask the output of capsule layer. For training\n    masked = Mask()(caps_layer1)  # Mask using the capsule with maximal length. For prediction\n\n    # Shared Decoder model in training and prediction\n    decoder = models.Sequential(name='decoder')\n    decoder.add(layers.Dense(512, activation='relu', input_dim=16 * n_class))\n    decoder.add(layers.Dense(1024, activation='relu'))\n    decoder.add(layers.Dense(np.prod(input_shape), activation='sigmoid'))\n    decoder.add(layers.Reshape(target_shape=input_shape, name='out_recon'))\n\n    # Models for training and evaluation (prediction)\n    train_model = models.Model([x, y], [out_caps, decoder(masked_by_y)])\n    eval_model = models.Model(x, [out_caps, decoder(masked)])\n\n    return train_model, eval_model #, manipulate_model\n\n\ndef margin_loss(y_true, y_pred):\n    \"\"\"\n    Margin loss for Eq.(4). When y_true[i, :] contains not just one `1`, this loss should work too. Not test it.\n    :param y_true: [None, n_classes]\n    :param y_pred: [None, num_capsule]\n    :return: a scalar loss value.\n    \"\"\"\n    L = y_true * tf.square(tf.maximum(0., 0.9 - y_pred)) + \\\n        0.5 * (1 - y_true) * tf.square(tf.maximum(0., y_pred - 0.1))\n    return tf.reduce_mean(tf.reduce_sum(L, 1))\n\n\ndef train(model, train_set, test_set, args, model_type='sv'):\n    \"\"\"\n    Training a CapsuleNet\n    :param model: the CapsuleNet model\n    :param train_set: data frame\n    :param test_set: data frame\n    :param args: arguments\n    :param model_type: argument\n    :return: The trained model\n    \"\"\"\n\n    # callbacks\n    log = callbacks.CSVLogger(args.save_dir + '/' + model_type + '-log.csv')\n    tb = callbacks.TensorBoard(\n        log_dir=args.save_dir + '/' + model_type + '-tensorboard-logs',\n        batch_size=args.batch_size, histogram_freq=int(args.debug)\n    )\n    checkpoint = callbacks.ModelCheckpoint(\n        args.save_dir + '/' + model_type + '-weights-{epoch:02d}.h5',\n        monitor='val_capsnet_acc',\n        save_best_only=True, save_weights_only=True, verbose=1\n    )\n    lr_decay = callbacks.LearningRateScheduler(schedule=lambda epoch: args.lr * (args.lr_decay ** epoch))\n    \n    output_layer_name = 'capsnet'\n    if model_type == 'mv' and args.mv_function == add_view_pooling:\n        output_layer_name = 'mv_capsnet'\n    \n    # compile the model\n    model.compile(\n        optimizer=optimizers.Adam(lr=args.lr),\n        loss=[margin_loss, 'mse'],\n        loss_weights=[1., args.lam_recon],\n        metrics={output_layer_name: ['accuracy']}\n    )\n\n    \"\"\"\n    # Training without data augmentation:\n    model.fit([x_train, y_train], [y_train, x_train], batch_size=args.batch_size, epochs=args.epochs,\n              validation_data=[[x_test, y_test], [y_test, x_test]], callbacks=[log, tb, checkpoint, lr_decay])\n    \"\"\"\n\n    # Begin: Training with data augmentation ---------------------------------------------------------------------#\n    def create_generator(df, batch_size, model_type='sv', n_views=None, shuffle=True):\n        data_gen = ImageDataGenerator(rescale=1. / 255)\n        if model_type == 'mv':\n            df = df.sort_values(FILE_PATH_COLUMN)\n            random_order = []\n            for obj_index in np.random.permutation(int(df.shape[0] / n_views)):\n                random_order += range(obj_index * n_views, (obj_index + 1) * n_views)\n            df['order'] = random_order\n            df = df.sort_values('order').drop('order', axis='columns')\n        generator = data_gen.flow_from_dataframe(\n            df, directory=WORK_DIR, x_col=FILE_PATH_COLUMN, y_col=CLASS_COLUMN,\n            target_size=(image_width, image_height), batch_size=batch_size,\n            shuffle=shuffle\n        )\n        while 1:\n            x_batch, y_batch = generator.next()\n            yield ([x_batch, y_batch], [y_batch, x_batch])\n\n    train_gen = create_generator(\n        train_set, args.batch_size, model_type, args.multi_view, shuffle='mv' != model_type\n    )\n    valid_gen = create_generator(\n        test_set, args.batch_size, model_type, args.multi_view, shuffle='mv' != model_type\n    )\n    f1_score = F1_score(\n        create_generator(\n            test_set, args.batch_size, model_type, args.multi_view, shuffle=False\n        ),\n        int(test_set.shape[0] / args.batch_size), args.save_dir, model_type, args.batch_size\n    )\n    # Training with data augmentation. If shift_fraction=0., also no augmentation.\n    model.fit_generator(\n        train_gen,\n        steps_per_epoch=int(len(train_set) / args.batch_size),\n        epochs=args.epochs,\n        validation_data=valid_gen,\n        validation_steps=int(test_set.shape[0] / args.batch_size),\n        callbacks=[log, tb, checkpoint, lr_decay, f1_score]\n    )\n\n    model.save_weights(args.save_dir + '/' + model_type + '-trained_model.h5')\n    print(\n        'Trained model saved to \\'%s/%s-trained_model.h5\\'' % (args.save_dir, model_type)\n    )\n\n    return model\n\n\ndef add_view_pooling(model, args):\n    capsnet = [layer for layer in model.layers if layer.name == 'capsnet'][0].output\n    view_pooling = ViewPoolingLayer(name='mv_capsnet', num_views=args.multi_view)(capsnet)\n    \n    decoder = [layer for layer in model.layers if layer.name == 'decoder'][0]\n    mask = [layer for layer in model.layers if layer.name == 'mask'][0].output\n    return models.Model(model.inputs, [view_pooling, decoder(mask)])\n\n\ndef add_view_capsule(model, args):\n    caps1 = [layer for layer in model.layers if layer.name == 'caps1'][0].output\n    view_caps = ViewCapsuleLayer(caps1, args.multi_view, 32, args.routings)\n    capsnet = [layer for layer in model.layers if layer.name == 'capsnet'][0](view_caps)\n    \n    decoder = [layer for layer in model.layers if layer.name == 'decoder'][0]\n    mask = [layer for layer in model.layers if layer.name == 'mask'][0].output\n    return models.Model(model.inputs, [capsnet, decoder(mask)])\n\n\ndef test(model, data):\n    test_datagen = ImageDataGenerator(rescale=1. / 255)\n    total_tp = 0\n    label_no = 0\n    for label in test_set[CLASS_COLUMN].unique():\n        label_data = data.query(f'{CLASS_COLUMN} == \"{label}\"')\n        test_generator = test_datagen.flow_from_dataframe(\n            label_data, directory=WORK_DIR, x_col=FILE_PATH_COLUMN, y_col=CLASS_COLUMN,\n            target_size=(image_width, image_height)\n        )\n        nb_samples = len(test_generator.filenames)\n        y_pred, recon = model.predict_generator(test_generator, steps=nb_samples)\n        tp = np.sum(np.argmax(np.unique(y_pred, axis=0), 1) == label_no)\n        print(f'Class {label} acc: {tp / label_data.shape[0]}')\n\n        total_tp += tp\n        label_no += 1\n    print('Test acc:', total_tp / data.shape[0])\n\n\ndef load_data():\n    train_set = []\n    test_set = []\n    classes = [\n        class_name for class_name in os.listdir(WORK_DIR)\n        if os.path.isdir(WORK_DIR + class_name)\n    ]\n    for class_name in classes:\n        n_rm = 0\n        if class_name == 'chair':\n            n_rm = 0\n#             n_rm = 7 # half\n        train_list = sorted(os.listdir(WORK_DIR + class_name + '/train'))\n#         train_list = train_list[:int(len(train_list) / 12 / 3 - n_rm) * 12]\n        for file in train_list:\n            train_set.append((class_name, class_name + '/train/' + file))\n        test_list = sorted(os.listdir(WORK_DIR + class_name + '/test'))\n        for file in test_list:\n            test_set.append((class_name, class_name + '/test/' + file))\n    return (\n        pd.DataFrame(train_set, columns=[CLASS_COLUMN, FILE_PATH_COLUMN]),\n        pd.DataFrame(test_set, columns=[CLASS_COLUMN, FILE_PATH_COLUMN])\n    )\n\n(train_set, test_set) = load_data()\n\n\ntrain_set = train_set.assign(\n    to_drop = lambda x: x[FILE_PATH_COLUMN].str.contains(\n        r'0565|0357|0536'\n    )\n) \\\n    .query(f'{CLASS_COLUMN} != \"chair\" or not to_drop') \\\n    .drop('to_drop', axis = 1)\n\ntest_set = test_set.assign(\n    to_drop = lambda x: x[FILE_PATH_COLUMN].str.contains(\n        r'chair_0905|car_0242|guitar_0205|airplane_0669.'\n    )\n) \\\n    .query('not to_drop').drop('to_drop', axis = 1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from tabulate import tabulate\n\n# print(tabulate(test_set.groupby('label').count().assign(obj_counts=lambda x: x.file_path / 12)[['obj_counts']], ['klasė', '3D objektų skaičius'], tablefmt='latex'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class args:\n    epochs = 12\n    batch_size = 8 * 12\n    lr = 0.001\n    lr_decay = 0.9\n    lam_recon = 0.392\n    routings = 3\n    shift_fraction = 0.\n    debug = False\n    save_dir = './experiment'\n    testing = False\n    weights = None\n    multi_view = 12\n#     mv_function = add_view_pooling # mv_capsnet_1\n    mv_function = add_view_capsule # mv_cap_capsnet_1\n#     multi_view = None # capsnet\n#     mv_function = None # capsnet\n    two_stage = False\n    \nprint(vars(args))\n\nif not os.path.exists(args.save_dir):\n    os.makedirs(args.save_dir)\n\nmodel, eval_model = CapsNet(\n    input_shape=(image_width, image_height, 3),\n    n_class=len(train_set[CLASS_COLUMN].unique()),\n    routings=args.routings,\n    batch_size=args.batch_size\n)\n\nif args.weights is not None:  # init the model weights with provided one\n    eval_model.load_weights(args.weights)\n    model.load_weights(args.weights)\n\nif not args.testing:\n    if args.two_stage or args.multi_view is None:\n        model.summary()\n        model = train(model=model, train_set=train_set, test_set=test_set, args=args)\n    \n    if args.multi_view:\n        model = args.mv_function(model, args)\n        model.summary()\n        train(\n            model=model, train_set=train_set, test_set=test_set,\n            args=args, model_type='mv'\n        )\n\nelse:  # as long as weights are given, will run testing\n    if args.weights is None:\n        print('No weights are provided. Will test using random initialized weights.')\n    test(model=eval_model, data=test_set)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# !pip install googledrivedownloader\n\n# from google_drive_downloader  import GoogleDriveDownloader as gdd\n\n# # https://drive.google.com/file/d//view?usp=sharing\n\n# gdd.download_file_from_google_drive(\n#     file_id='1UXD1vVzGoSl7-GRut4LdT4LKWSm1O1PC',\n#     dest_path='./res.txt'\n# )","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}