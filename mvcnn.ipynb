{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, name):\n",
    "        super(Model, self).__init__()\n",
    "        self.name = name\n",
    "\n",
    "\n",
    "    def save(self, path, epoch=0):\n",
    "        complete_path = os.path.join(path, self.name)\n",
    "        if not os.path.exists(complete_path):\n",
    "            os.makedirs(complete_path)\n",
    "        torch.save(self.state_dict(), \n",
    "                os.path.join(complete_path, \n",
    "                    \"model-{}.pth\".format(str(epoch).zfill(5))))\n",
    "\n",
    "\n",
    "    def save_results(self, path, data):\n",
    "        raise NotImplementedError(\"Model subclass must implement this method.\")\n",
    "        \n",
    "\n",
    "    def load(self, path, modelfile=None):\n",
    "        complete_path = os.path.join(path, self.name)\n",
    "        if not os.path.exists(complete_path):\n",
    "            raise IOError(\"{} directory does not exist in {}\".format(self.name, path))\n",
    "\n",
    "        if modelfile is None:\n",
    "            model_files = glob.glob(complete_path+\"/*\")\n",
    "            mf = max(model_files)\n",
    "        else:\n",
    "            mf = os.path.join(complete_path, modelfile)\n",
    "\n",
    "        self.load_state_dict(torch.load(mf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.models as models\n",
    "\n",
    "mean = Variable(torch.FloatTensor([0.485, 0.456, 0.406]), requires_grad=False).cuda()\n",
    "std = Variable(torch.FloatTensor([0.229, 0.224, 0.225]), requires_grad=False).cuda()\n",
    "\n",
    "def flip(x, dim):\n",
    "    xsize = x.size()\n",
    "    dim = x.dim() + dim if dim < 0 else dim\n",
    "    x = x.view(-1, *xsize[dim:])\n",
    "    x = x.view(x.size(0), x.size(1), -1)[:, getattr(torch.arange(x.size(1)-1, \n",
    "                      -1, -1), ('cpu','cuda')[x.is_cuda])().long(), :]\n",
    "    return x.view(xsize)\n",
    "\n",
    "\n",
    "class SVCNN(Model):\n",
    "\n",
    "    def __init__(self, name, nclasses=40, pretraining=True, cnn_name='vgg11'):\n",
    "        super(SVCNN, self).__init__(name)\n",
    "\n",
    "        self.classnames=['airplane','bathtub','bed','bench','bookshelf','bottle','bowl','car','chair',\n",
    "                         'cone','cup','curtain','desk','door','dresser','flower_pot','glass_box',\n",
    "                         'guitar','keyboard','lamp','laptop','mantel','monitor','night_stand',\n",
    "                         'person','piano','plant','radio','range_hood','sink','sofa','stairs',\n",
    "                         'stool','table','tent','toilet','tv_stand','vase','wardrobe','xbox']\n",
    "\n",
    "        self.nclasses = nclasses\n",
    "        self.pretraining = pretraining\n",
    "        self.cnn_name = cnn_name\n",
    "        self.use_resnet = cnn_name.startswith('resnet')\n",
    "        self.mean = Variable(torch.FloatTensor([0.485, 0.456, 0.406]), requires_grad=False).cuda()\n",
    "        self.std = Variable(torch.FloatTensor([0.229, 0.224, 0.225]), requires_grad=False).cuda()\n",
    "\n",
    "        if self.use_resnet:\n",
    "            if self.cnn_name == 'resnet18':\n",
    "                self.net = models.resnet18(pretrained=self.pretraining)\n",
    "                self.net.fc = nn.Linear(512,40)\n",
    "            elif self.cnn_name == 'resnet34':\n",
    "                self.net = models.resnet34(pretrained=self.pretraining)\n",
    "                self.net.fc = nn.Linear(512,40)\n",
    "            elif self.cnn_name == 'resnet50':\n",
    "                self.net = models.resnet50(pretrained=self.pretraining)\n",
    "                self.net.fc = nn.Linear(2048,40)\n",
    "        else:\n",
    "            if self.cnn_name == 'alexnet':\n",
    "                self.net_1 = models.alexnet(pretrained=self.pretraining).features\n",
    "                self.net_2 = models.alexnet(pretrained=self.pretraining).classifier\n",
    "            elif self.cnn_name == 'vgg11':\n",
    "                self.net_1 = models.vgg11(pretrained=self.pretraining).features\n",
    "                self.net_2 = models.vgg11(pretrained=self.pretraining).classifier\n",
    "            elif self.cnn_name == 'vgg16':\n",
    "                self.net_1 = models.vgg16(pretrained=self.pretraining).features\n",
    "                self.net_2 = models.vgg16(pretrained=self.pretraining).classifier\n",
    "            \n",
    "            self.net_2._modules['6'] = nn.Linear(4096,40)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.use_resnet:\n",
    "            return self.net(x)\n",
    "        else:\n",
    "            y = self.net_1(x)\n",
    "            return self.net_2(y.view(y.shape[0],-1))\n",
    "\n",
    "\n",
    "class MVCNN(Model):\n",
    "\n",
    "    def __init__(self, name, model, nclasses=40, cnn_name='vgg11', num_views=12):\n",
    "        super(MVCNN, self).__init__(name)\n",
    "\n",
    "        self.classnames=['airplane','bathtub','bed','bench','bookshelf','bottle','bowl','car','chair',\n",
    "                         'cone','cup','curtain','desk','door','dresser','flower_pot','glass_box',\n",
    "                         'guitar','keyboard','lamp','laptop','mantel','monitor','night_stand',\n",
    "                         'person','piano','plant','radio','range_hood','sink','sofa','stairs',\n",
    "                         'stool','table','tent','toilet','tv_stand','vase','wardrobe','xbox']\n",
    "\n",
    "        self.nclasses = nclasses\n",
    "        self.num_views = num_views\n",
    "        self.mean = Variable(torch.FloatTensor([0.485, 0.456, 0.406]), requires_grad=False).cuda()\n",
    "        self.std = Variable(torch.FloatTensor([0.229, 0.224, 0.225]), requires_grad=False).cuda()\n",
    "\n",
    "        self.use_resnet = cnn_name.startswith('resnet')\n",
    "\n",
    "        if self.use_resnet:\n",
    "            self.net_1 = nn.Sequential(*list(model.net.children())[:-1])\n",
    "            self.net_2 = model.net.fc\n",
    "        else:\n",
    "            self.net_1 = model.net_1\n",
    "            self.net_2 = model.net_2\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.net_1(x)\n",
    "        y = y.view((int(x.shape[0]/self.num_views),self.num_views,y.shape[-3],y.shape[-2],y.shape[-1]))#(8,12,512,7,7)\n",
    "        return self.net_2(torch.max(y,1)[0].view(y.shape[0],-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "from tensorboardX import SummaryWriter\n",
    "import time\n",
    "\n",
    "class ModelNetTrainer(object):\n",
    "\n",
    "    def __init__(self, model, train_loader, val_loader, optimizer, loss_fn, \\\n",
    "                 model_name, log_dir, num_views=12):\n",
    "\n",
    "        self.optimizer = optimizer\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.loss_fn = loss_fn\n",
    "        self.model_name = model_name\n",
    "        self.log_dir = log_dir\n",
    "        self.num_views = num_views\n",
    "\n",
    "        self.model.cuda()\n",
    "        if self.log_dir is not None:\n",
    "            self.writer = SummaryWriter(log_dir)\n",
    "\n",
    "\n",
    "    def train(self, n_epochs):\n",
    "\n",
    "        best_acc = 0\n",
    "        i_acc = 0\n",
    "        stats = pd.DataFrame({'epoch': [], 'train_acc': [], 'acc_per_class': [], 'acc': [], 'loss': []})\n",
    "        self.model.train()\n",
    "        for epoch in range(n_epochs):\n",
    "            all_train_correct_points = 0\n",
    "            all_train_points = 0\n",
    "            \n",
    "            # permute data for mvcnn\n",
    "            rand_idx = np.random.permutation(int(len(self.train_loader.dataset.filepaths)/self.num_views))\n",
    "            filepaths_new = []\n",
    "            for i in range(len(rand_idx)):\n",
    "                filepaths_new.extend(\n",
    "                    self.train_loader.dataset.filepaths[rand_idx[i]*self.num_views:(rand_idx[i]+1)*self.num_views]\n",
    "                )\n",
    "            self.train_loader.dataset.filepaths = filepaths_new\n",
    "\n",
    "            # plot learning rate\n",
    "            lr = self.optimizer.state_dict()['param_groups'][0]['lr']\n",
    "            self.writer.add_scalar('params/lr', lr, epoch)\n",
    "\n",
    "            # train one epoch\n",
    "            out_data = None\n",
    "            in_data = None\n",
    "            for i, data in enumerate(self.train_loader):\n",
    "\n",
    "                if self.model_name == 'mvcnn':\n",
    "                    N,V,C,H,W = data[1].size()\n",
    "                    in_data = Variable(data[1]).view(-1,C,H,W).cuda()\n",
    "                else:\n",
    "                    in_data = Variable(data[1].cuda())\n",
    "                target = Variable(data[0]).cuda().long()\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                out_data = self.model(in_data)\n",
    "\n",
    "                loss = self.loss_fn(out_data, target)\n",
    "                \n",
    "                self.writer.add_scalar('train/train_loss', loss, i_acc+i+1)\n",
    "\n",
    "                pred = torch.max(out_data, 1)[1]\n",
    "                results = pred == target\n",
    "                correct_points = torch.sum(results.long()).float()\n",
    "                acc = correct_points/results.size()[0]\n",
    "                \n",
    "                all_train_correct_points += correct_points\n",
    "                all_train_points += results.size()[0]\n",
    "                overall_acc = all_train_correct_points/all_train_points\n",
    "                \n",
    "                self.writer.add_scalar('train/train_overall_acc', acc, i_acc+i+1)\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                log_str = 'epoch %d, step %d: train_loss %.3f; train_acc %.3f' % (epoch+1, i+1, loss, overall_acc)\n",
    "                \n",
    "                if (i+1)%1==0:\n",
    "                    print(log_str)\n",
    "            i_acc += i\n",
    "\n",
    "            # evaluation\n",
    "            if (epoch+1)%1==0:\n",
    "                with torch.no_grad():\n",
    "                    loss, val_overall_acc, val_mean_class_acc = self.update_validation_accuracy(epoch)\n",
    "                self.writer.add_scalar('val/val_mean_class_acc', val_mean_class_acc, epoch+1)\n",
    "                self.writer.add_scalar('val/val_overall_acc', val_overall_acc, epoch+1)\n",
    "                self.writer.add_scalar('val/val_loss', loss, epoch+1)\n",
    "            stats = stats.append(\n",
    "                pd.DataFrame({\n",
    "                    'epoch': [epoch], 'train_acc': overall_acc.item(),\n",
    "                    'acc_per_class': val_mean_class_acc,\n",
    "                    'acc': val_overall_acc, 'loss': loss.item()\n",
    "                })\n",
    "             )\n",
    "            stats.to_csv(self.log_dir + '/logs.csv', index=False)\n",
    "\n",
    "            # save best model\n",
    "            if val_overall_acc > best_acc:\n",
    "                best_acc = val_overall_acc\n",
    "                self.model.save(self.log_dir, epoch)\n",
    " \n",
    "            # adjust learning rate manually\n",
    "            if epoch > 0 and (epoch+1) % 10 == 0:\n",
    "                for param_group in self.optimizer.param_groups:\n",
    "                    param_group['lr'] = param_group['lr']*0.5\n",
    "\n",
    "        # export scalar data to JSON for external processing\n",
    "        self.writer.export_scalars_to_json(self.log_dir+\"/all_scalars.json\")\n",
    "        self.writer.close()\n",
    "\n",
    "    def update_validation_accuracy(self, epoch):\n",
    "        all_correct_points = 0\n",
    "        all_points = 0\n",
    "\n",
    "        # in_data = None\n",
    "        # out_data = None\n",
    "        # target = None\n",
    "\n",
    "        wrong_class = np.zeros(40)\n",
    "        samples_class = np.zeros(40)\n",
    "        all_loss = 0\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "        avgpool = nn.AvgPool1d(1, 1)\n",
    "\n",
    "        total_time = 0.0\n",
    "        total_print_time = 0.0\n",
    "        all_target = []\n",
    "        all_pred = []\n",
    "\n",
    "        for _, data in enumerate(self.val_loader, 0):\n",
    "\n",
    "            if self.model_name == 'mvcnn':\n",
    "                N,V,C,H,W = data[1].size()\n",
    "                in_data = Variable(data[1]).view(-1,C,H,W).cuda()\n",
    "            else:#'svcnn'\n",
    "                in_data = Variable(data[1]).cuda()\n",
    "            target = Variable(data[0]).cuda()\n",
    "\n",
    "            out_data = self.model(in_data)\n",
    "            pred = torch.max(out_data, 1)[1]\n",
    "            all_loss += self.loss_fn(out_data, target).cpu().data.numpy()\n",
    "            results = pred == target\n",
    "\n",
    "            for i in range(results.size()[0]):\n",
    "                if not bool(results[i].cpu().data.numpy()):\n",
    "                    wrong_class[target.cpu().data.numpy().astype('int')[i]] += 1\n",
    "                samples_class[target.cpu().data.numpy().astype('int')[i]] += 1\n",
    "            correct_points = torch.sum(results.long())\n",
    "\n",
    "            all_correct_points += correct_points\n",
    "            all_points += results.size()[0]\n",
    "\n",
    "        print ('Total # of test models: ', all_points)\n",
    "        val_mean_class_acc = np.mean((samples_class-wrong_class)/samples_class)\n",
    "        acc = all_correct_points.float() / all_points\n",
    "        val_overall_acc = acc.cpu().data.numpy()\n",
    "        loss = all_loss / len(self.val_loader)\n",
    "\n",
    "        print ('val mean class acc. : ', val_mean_class_acc)\n",
    "        print ('val overall acc. : ', val_overall_acc)\n",
    "        print ('val loss : ', loss)\n",
    "\n",
    "        self.model.train()\n",
    "\n",
    "        return loss, val_overall_acc, val_mean_class_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import torch.utils.data\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "from skimage import io, transform\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision as vision\n",
    "from torchvision import transforms, datasets\n",
    "import random\n",
    "\n",
    "class MultiviewImgDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, root_dir, scale_aug=False, rot_aug=False, test_mode=False, \\\n",
    "                 num_models=0, num_views=12, shuffle=True):\n",
    "        self.classnames=['airplane','bathtub','bed','bench','bookshelf','bottle','bowl','car','chair',\n",
    "                         'cone','cup','curtain','desk','door','dresser','flower_pot','glass_box',\n",
    "                         'guitar','keyboard','lamp','laptop','mantel','monitor','night_stand',\n",
    "                         'person','piano','plant','radio','range_hood','sink','sofa','stairs',\n",
    "                         'stool','table','tent','toilet','tv_stand','vase','wardrobe','xbox']\n",
    "        self.root_dir = root_dir\n",
    "        self.scale_aug = scale_aug\n",
    "        self.rot_aug = rot_aug\n",
    "        self.test_mode = test_mode\n",
    "        self.num_views = num_views\n",
    "\n",
    "        set_ = root_dir.split('/')[-1]\n",
    "        parent_dir = root_dir.rsplit('/',2)[0]\n",
    "        self.filepaths = []\n",
    "        for i in range(len(self.classnames)):\n",
    "            all_files = sorted(glob.glob(parent_dir+'/'+self.classnames[i]+'/'+set_+'/*.png'))\n",
    "            ## Select subset for different number of views\n",
    "            stride = int(12/self.num_views) # 12 6 4 3 2 1\n",
    "            all_files = all_files[::stride]\n",
    "\n",
    "            if num_models == 0:\n",
    "                # Use the whole dataset\n",
    "                self.filepaths.extend(all_files)\n",
    "            else:\n",
    "                self.filepaths.extend(all_files[:min(num_models,len(all_files))])\n",
    "\n",
    "        self.filepaths = [\n",
    "            file for file in self.filepaths\n",
    "            if not re.search(\n",
    "                r'train/chair_0565|train/chair_0357|train/chair_0536|test/chair_0905|test/car_0242|test/guitar_0205|test/airplane_0669',\n",
    "                file\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        if shuffle==True:\n",
    "            # permute\n",
    "            rand_idx = np.random.permutation(int(len(self.filepaths)/num_views))\n",
    "            filepaths_new = []\n",
    "            for i in range(len(rand_idx)):\n",
    "                filepaths_new.extend(self.filepaths[rand_idx[i]*num_views:(rand_idx[i]+1)*num_views])\n",
    "            self.filepaths = filepaths_new\n",
    "\n",
    "\n",
    "        if self.test_mode:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "            ])    \n",
    "        else:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "            ])\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(len(self.filepaths)/self.num_views)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.filepaths[idx*self.num_views]\n",
    "        class_name = path.split('/')[-3]\n",
    "        class_id = self.classnames.index(class_name)\n",
    "        # Use PIL instead\n",
    "        imgs = []\n",
    "        for i in range(self.num_views):\n",
    "            im = Image.open(self.filepaths[idx*self.num_views+i]).convert('RGB')\n",
    "            if self.transform:\n",
    "                im = self.transform(im)\n",
    "            imgs.append(im)\n",
    "\n",
    "        return (class_id, torch.stack(imgs), self.filepaths[idx*self.num_views:(idx+1)*self.num_views])\n",
    "\n",
    "\n",
    "\n",
    "class SingleImgDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, root_dir, scale_aug=False, rot_aug=False, test_mode=False, \\\n",
    "                 num_models=0, num_views=12):\n",
    "        self.classnames=['airplane','bathtub','bed','bench','bookshelf','bottle','bowl','car','chair',\n",
    "                         'cone','cup','curtain','desk','door','dresser','flower_pot','glass_box',\n",
    "                         'guitar','keyboard','lamp','laptop','mantel','monitor','night_stand',\n",
    "                         'person','piano','plant','radio','range_hood','sink','sofa','stairs',\n",
    "                         'stool','table','tent','toilet','tv_stand','vase','wardrobe','xbox']\n",
    "        self.root_dir = root_dir\n",
    "        self.scale_aug = scale_aug\n",
    "        self.rot_aug = rot_aug\n",
    "        self.test_mode = test_mode\n",
    "\n",
    "        set_ = root_dir.split('/')[-1]\n",
    "        parent_dir = root_dir.rsplit('/',2)[0]\n",
    "        self.filepaths = []\n",
    "        for i in range(len(self.classnames)):\n",
    "            all_files = sorted(glob.glob(parent_dir+'/'+self.classnames[i]+'/'+set_+'/*shaded*.png'))\n",
    "            if num_models == 0:\n",
    "                # Use the whole dataset\n",
    "                self.filepaths.extend(all_files)\n",
    "            else:\n",
    "                self.filepaths.extend(all_files[:min(num_models,len(all_files))])\n",
    "\n",
    "        self.filepaths = [\n",
    "            file for file in self.filepaths\n",
    "            if not re.search(\n",
    "                r'train/chair_0565|train/chair_0357|train/chair_0536|test/chair_0905|test/car_0242|test/guitar_0205|test/airplane_0669',\n",
    "                file\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filepaths)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.filepaths[idx]\n",
    "        class_name = path.split('/')[-3]\n",
    "        class_id = self.classnames.index(class_name)\n",
    "\n",
    "        # Use PIL instead\n",
    "        im = Image.open(self.filepaths[idx]).convert('RGB')\n",
    "        if self.transform:\n",
    "            im = self.transform(im)\n",
    "\n",
    "        return (class_id, im, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "68cbe032-c98e-4e17-8dd5-5c726b17bad5",
    "_uuid": "cb2e4b06-32f3-446c-9465-304f565369ef"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import os,shutil,json\n",
    "import argparse\n",
    "\n",
    "\n",
    "class args:\n",
    "    name = 'mvcnn'\n",
    "    batchSize = 8\n",
    "    num_models = 0\n",
    "    lr = 5e-5\n",
    "    weight_decay = 0.0\n",
    "    no_pretraining = True\n",
    "    cnn_name = 'vgg11'\n",
    "    num_views = 12\n",
    "    train_path = './../input/views-rendered-from-3d-models/cleaned.dataset/*/train'\n",
    "    val_path = './../input/views-rendered-from-3d-models/cleaned.dataset/*/test'\n",
    "\n",
    "\n",
    "def create_folder(log_dir):\n",
    "    # make summary folder\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.mkdir(log_dir)\n",
    "    else:\n",
    "        print('WARNING: summary folder already exists!! It will be overwritten!!')\n",
    "        shutil.rmtree(log_dir)\n",
    "        os.mkdir(log_dir)\n",
    "\n",
    "\n",
    "print('starting ...')\n",
    "        \n",
    "pretraining = not args.no_pretraining\n",
    "log_dir = args.name\n",
    "create_folder(args.name)\n",
    "\n",
    "# STAGE 1\n",
    "log_dir = args.name+'_stage_1'\n",
    "create_folder(log_dir)\n",
    "cnet = SVCNN(args.name, nclasses=40, pretraining=pretraining, cnn_name=args.cnn_name)\n",
    "\n",
    "optimizer = optim.Adam(cnet.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "\n",
    "n_models_train = args.num_models*args.num_views\n",
    "\n",
    "train_dataset = SingleImgDataset(args.train_path, scale_aug=False, rot_aug=False, num_models=n_models_train, num_views=args.num_views)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batchSize * args.num_views, shuffle=True, num_workers=0)\n",
    "\n",
    "val_dataset = SingleImgDataset(args.val_path, scale_aug=False, rot_aug=False, test_mode=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=args.batchSize * args.num_views, shuffle=False, num_workers=0)\n",
    "print('num_train_files: '+str(len(train_dataset.filepaths)))\n",
    "print('num_val_files: '+str(len(val_dataset.filepaths)))\n",
    "trainer = ModelNetTrainer(cnet, train_loader, val_loader, optimizer, nn.CrossEntropyLoss(), 'svcnn', log_dir, num_views=1)\n",
    "trainer.train(5)\n",
    "\n",
    "# STAGE 2\n",
    "log_dir = args.name+'_stage_2'\n",
    "create_folder(log_dir)\n",
    "cnet_2 = MVCNN(args.name, cnet, nclasses=40, cnn_name=args.cnn_name, num_views=args.num_views)\n",
    "del cnet\n",
    "\n",
    "optimizer = optim.Adam(cnet_2.parameters(), lr=args.lr, weight_decay=args.weight_decay, betas=(0.9, 0.999))\n",
    "\n",
    "train_dataset = MultiviewImgDataset(args.train_path, scale_aug=False, rot_aug=False, num_models=n_models_train, num_views=args.num_views)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batchSize, shuffle=False, num_workers=0)# shuffle needs to be false! it's done within the trainer\n",
    "\n",
    "val_dataset = MultiviewImgDataset(args.val_path, scale_aug=False, rot_aug=False, num_views=args.num_views)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=args.batchSize, shuffle=False, num_workers=0)\n",
    "print('num_train_files: '+str(len(train_dataset.filepaths)))\n",
    "print('num_val_files: '+str(len(val_dataset.filepaths)))\n",
    "trainer = ModelNetTrainer(cnet_2, train_loader, val_loader, optimizer, nn.CrossEntropyLoss(), 'mvcnn', log_dir, num_views=args.num_views)\n",
    "trainer.train(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
